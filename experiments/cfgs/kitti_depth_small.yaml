# Kitti dataset layout (symlinks to flat layout)
# ./data/kitti/00001/label.binvox
# ./data/kitti/00001/renderings.txt
# ./data/kitti/00001/00.png
# ./data/kitti/00001/01.png
# ...
# ./data/kitti/00005/label.binvox
# ...
DATASET: './experiments/dataset/kitti.json'
DIR:
    # data_io.py: Used with single category id 'kitti' (from kitti.json) to list examples ('00001' etc.).
    SHAPENET_QUERY_PATH: './data'
    # data_io.py: (category, model_id)
    VOXEL_PATH: './data/{0}/{1}/label.binvox'
    # data_io.py: return os.path.join(cfg.DIR.RENDERING_PATH % (category, model_id), '%02d.png' % rendering_id)
    # rendering_id are generated from NUM_RENDERING
    RENDERING_PATH: './data/{0}/{1}'
CONST:
    # Set batch size as argument to main.py (different in train/test)
    # __C.CONST.BATCH_SIZE = 36
    # BATCH_SIZE: 36
    IMG_DEPTH: True
    IMG_W: 160
    IMG_H: 120
    N_VOX: [32, 32, 32]
    # data_process.py: Number of views to be used, should be fixed and equal to the number of rendered depths.
    N_VIEWS: 5
TRAIN:
    # data_process.py: Number of renderings per model
    NUM_RENDERING: 5
    RANDOM_CROP: False
    PAD_X: 0
    PAD_Y: 0
    FLIP: False
    MOMENTUM: 0.9
    # MOMENTUM: 0.99
    POLICY: 'adam'  # def: sgd, adam
    # For SGD use 0.1, for ADAM, use 0.0001
    DEFAULT_LEARNING_RATE: 0.0001
    LEARNING_RATES: {'20000': 0.00001, '60000': 0.000001}
    # DEFAULT_LEARNING_RATE: 0.1
    # LEARNING_RATES: {'20000': 0.01, '60000': 0.001}

